{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtain the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE! Please run the cells in order, lots of variables are reused and reassigned. Values may wary based on order of execution.\n"
     ]
    }
   ],
   "source": [
    "#Run this code block, Don't change anything\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cal = datasets.fetch_california_housing()\n",
    "X = cal.data\n",
    "y = cal.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=0)\n",
    "y_bool_train = [i > 1.8 for i in y_train]\n",
    "y_bool_test = [i > 1.8 for i in y_test]\n",
    "\n",
    "print(\"NOTE! Please run the cells in order, lots of variables are reused and reassigned. Values may wary based on order of execution.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1a."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "Top 5 results based on the gridsearch:\n",
      "\n",
      "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
      "28      13.321992      0.080406         0.043624        0.025154   \n",
      "27      10.395087      0.150640         0.025706        0.002930   \n",
      "22      12.703906      0.083156         0.034053        0.001696   \n",
      "29      13.715162      0.909250         0.037243        0.000655   \n",
      "21      10.092182      0.040122         0.024983        0.001360   \n",
      "\n",
      "   param_learning_rate param_max_depth  \\\n",
      "28                0.05               9   \n",
      "27                0.05               7   \n",
      "22                0.04               9   \n",
      "29                0.05              11   \n",
      "21                0.04               7   \n",
      "\n",
      "                                      params  split0_test_score  \\\n",
      "28   {'learning_rate': 0.05, 'max_depth': 9}           0.814435   \n",
      "27   {'learning_rate': 0.05, 'max_depth': 7}           0.813678   \n",
      "22   {'learning_rate': 0.04, 'max_depth': 9}           0.806598   \n",
      "29  {'learning_rate': 0.05, 'max_depth': 11}           0.798741   \n",
      "21   {'learning_rate': 0.04, 'max_depth': 7}           0.807349   \n",
      "\n",
      "    split1_test_score  split2_test_score  split3_test_score  \\\n",
      "28           0.827439           0.814268           0.829936   \n",
      "27           0.823640           0.811583           0.823856   \n",
      "22           0.822627           0.809828           0.822911   \n",
      "29           0.812630           0.802472           0.824071   \n",
      "21           0.816710           0.805907           0.815679   \n",
      "\n",
      "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
      "28           0.828183         0.822852        0.006988                1  \n",
      "27           0.817761         0.818104        0.005019                2  \n",
      "22           0.821773         0.816748        0.007053                3  \n",
      "29           0.818813         0.811345        0.009560                4  \n",
      "21           0.809821         0.811093        0.004362                5  \n"
     ]
    }
   ],
   "source": [
    "# !pip install xgboost\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# model = GradientBoostingClassifier(random_state=0)\n",
    "\n",
    "X_train_gb = X_train\n",
    "Y_train_gb = y_train\n",
    "\n",
    "param_distributions = {\n",
    "    \"learning_rate\": [0.01, 0.02, 0.03, 0.04, 0.05],\n",
    "    \"max_depth\": [1,3,5,7,9,11]\n",
    "}\n",
    "grid_search_val = GridSearchCV(\n",
    "    GradientBoostingRegressor(), param_distributions, verbose=1, n_jobs=-1, cv=5\n",
    ")\n",
    "grid_search_val.fit(X_train_gb, Y_train_gb) \n",
    "# grid_search_val.fit(X_train,y_train) \n",
    "grid_search_val.best_params_\n",
    "grid_search_val.best_estimator_ \n",
    "\n",
    "cv_results = pd.DataFrame(grid_search_val.cv_results_)\n",
    "print(\"Top 5 results based on the gridsearch:\\n\\n\", cv_results.nlargest(5, \"mean_test_score\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1a. Conclusion:\n",
      "\n",
      "Best parameters based on the grid search\n",
      "  {'learning_rate': 0.05, 'max_depth': 9}\n",
      "\n",
      "Best estimator/classifier from the grid search\n",
      "  GradientBoostingRegressor(learning_rate=0.05, max_depth=9)\n",
      "\n",
      "Determination coefficient(r2) score on test set is 0.7885693134153988 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Q1a. Conclusion:')\n",
    "print('\\nBest parameters based on the grid search')\n",
    "print(' ', grid_search_val.best_params_)\n",
    "print('\\nBest estimator/classifier from the grid search')\n",
    "print(' ', grid_search_val.best_estimator_) \n",
    "\n",
    "predictions = grid_search_val.best_estimator_.predict(X_test) \n",
    "\n",
    "print('\\nDetermination coefficient(r2) score on test set is {} '.format(r2_score(predictions, y_test))) \n",
    "\n",
    "print()\n",
    "# grid_search_val.get_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1b."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
      "0       2.070876      0.279791         0.005747        0.001099   \n",
      "1       5.454230      0.030458         0.011555        0.000895   \n",
      "2       7.789216      0.076201         0.017231        0.000218   \n",
      "3      10.298696      0.046296         0.025480        0.000503   \n",
      "4      12.646030      0.056151         0.035078        0.001189   \n",
      "\n",
      "  param_learning_rate param_max_depth  \\\n",
      "0                0.01               1   \n",
      "1                0.01               3   \n",
      "2                0.01               5   \n",
      "3                0.01               7   \n",
      "4                0.01               9   \n",
      "\n",
      "                                    params  split0_test_score  \\\n",
      "0  {'learning_rate': 0.01, 'max_depth': 1}           0.332965   \n",
      "1  {'learning_rate': 0.01, 'max_depth': 3}           0.514781   \n",
      "2  {'learning_rate': 0.01, 'max_depth': 5}           0.594032   \n",
      "3  {'learning_rate': 0.01, 'max_depth': 7}           0.634171   \n",
      "4  {'learning_rate': 0.01, 'max_depth': 9}           0.663675   \n",
      "\n",
      "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
      "0           0.328395           0.320404           0.321414           0.330878   \n",
      "1           0.509878           0.505845           0.503742           0.506388   \n",
      "2           0.590182           0.587920           0.589642           0.585653   \n",
      "3           0.638841           0.633413           0.639417           0.633717   \n",
      "4           0.669288           0.659667           0.668325           0.664897   \n",
      "\n",
      "   mean_test_score  std_test_score  rank_test_score  \n",
      "0         0.326811        0.005042               30  \n",
      "1         0.508127        0.003868               27  \n",
      "2         0.589486        0.002769               24  \n",
      "3         0.635912        0.002644               22  \n",
      "4         0.665170        0.003450               21  \n",
      "\n",
      "Selecting values mean_test_score, param_learning_rate and param_max_depth from the grid search results.\n"
     ]
    }
   ],
   "source": [
    "cv_results = pd.DataFrame(grid_search_val.cv_results_)\n",
    "print(cv_results.head())\n",
    "\n",
    "print()\n",
    "print(\"Selecting values mean_test_score, param_learning_rate and param_max_depth from the grid search results.\")\n",
    "r2_score_list = cv_results['mean_test_score']\n",
    "learning_rate_plot = cv_results['param_learning_rate']\n",
    "depth_row_plot = cv_results['param_max_depth']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1b. conclusion:\n",
      "From the graph, we can see that initially increasing value of depth and learning rate shows massive improvement in the performance, but after a certaing value the gains plateau, we only see minimal improvements with increasing depth and learning_rate. Finally, we see a decline in performance post a certain limit showing that there is a balance of both depth and learning rate that is necessary to be maintained, and infinitely increasing values doesnt work and even results in decline of performance.\n"
     ]
    }
   ],
   "source": [
    "plt.plot(depth_row_plot[0:6], r2_score_list[0:6], label=\"0.01\")\n",
    "plt.plot(depth_row_plot[6:12], r2_score_list[6:12], label=\"0.02\")\n",
    "plt.plot(depth_row_plot[12:18], r2_score_list[12:18], label=\"0.03\")\n",
    "plt.plot(depth_row_plot[18:24], r2_score_list[18:24], label=\"0.04\")\n",
    "plt.plot(depth_row_plot[24:30], r2_score_list[24:30], label=\"0.05\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Depth\")\n",
    "plt.ylabel(\"r2 score\")\n",
    "plt.show()\n",
    "print('Q1b. conclusion:')\n",
    "print('From the graph, we can see that initially increasing value of depth and learning rate shows massive improvement in the performance, but after a certaing value the gains plateau, we only see minimal improvements with increasing depth and learning_rate. Finally, we see a decline in performance post a certain limit showing that there is a balance of both depth and learning rate that is necessary to be maintained, and infinitely increasing values doesnt work and even results in decline of performance.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1c."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1c) \n",
      "\n",
      "Methods to further improve performance\n",
      "\n",
      "a) Feature selection and scaling: Thinning the number of values that positively affect and are correlated to the overall price. Once selected, we standardize the value ranges to improve the performance further.\n",
      "\n",
      "b) Boosting algorithms: Sequentially training multiple models to increase accuracy is a better way to move forward.\n",
      "\n",
      "c) Further Hyperparameter Tuning: Trying different loss functions, subsampling values to increase or reduce bias and variance, different criterion etc.\n",
      "\n",
      "d) Number of trees: Finding the right amount trees prevent overfitting and underfitting values.\n"
     ]
    }
   ],
   "source": [
    "print('Q1c) \\n')\n",
    "print('Methods to further improve performance')\n",
    "print('\\na) Feature selection and scaling: Thinning the number of values that positively affect and are correlated to the overall price. Once selected, we standardize the value ranges to improve the performance further.')\n",
    "print('\\nb) Boosting algorithms: Sequentially training multiple models to increase accuracy is a better way to move forward.')\n",
    "print('\\nc) Further Hyperparameter Tuning: Trying different loss functions, subsampling values to increase or reduce bias and variance, different criterion etc.')\n",
    "print('\\nd) Number of trees: Finding the right amount trees prevent overfitting and underfitting values.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2a."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models used here are:\n",
      "-  LogisticRegression(solver='liblinear')\n",
      "-  DecisionTreeClassifier()\n",
      "-  KNeighborsClassifier()\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "print(\"Models used here are:\")\n",
    "logit = LogisticRegression(solver='liblinear')\n",
    "print(\"- \", logit)\n",
    "logit.fit(X_train, y_bool_train)\n",
    "# predicted = cross_validation.cross_val_predict(logit, X_train, y_bool_train, cv=10)\n",
    "logit_score = cross_val_score(logit, X_train, y_bool_train, cv=5, scoring='f1')\n",
    "\n",
    "dTree = DecisionTreeClassifier()\n",
    "print(\"- \", dTree)\n",
    "dTree_score = cross_val_score(dTree, X_train, y_bool_train, cv=5, scoring='f1')\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "print(\"- \", knn)\n",
    "knn_score = cross_val_score(dTree, X_train, y_bool_train, cv=5, scoring='f1')\n",
    "# print(metrics.classification_report(y_train, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q2a. conclusion:\n",
      "\n",
      "Logistic regression cross validation score\n",
      "0.8059569251928537\n",
      "\n",
      "\n",
      "DecisionTreeClassifier cross validation score\n",
      "0.8359640774510414\n",
      "\n",
      "\n",
      "KNeighborsClassifier cross validation score\n",
      "0.8371371947370714\n"
     ]
    }
   ],
   "source": [
    "print('Q2a. conclusion:')\n",
    "\n",
    "print(\"\\nLogistic regression cross validation score\")\n",
    "print(logit_score.mean())\n",
    "print()\n",
    "\n",
    "print(\"\\nDecisionTreeClassifier cross validation score\")\n",
    "print(dTree_score.mean())\n",
    "print()\n",
    "\n",
    "print(\"\\nKNeighborsClassifier cross validation score\")\n",
    "print(knn_score.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2b."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of all the tunable parameters in the decision trees. I narrowed down to 4 parameters for the following reasons:\n",
      "\n",
      " - Criterion: This decides which criteria to consider while considering a split to a more specific subset, Gini and entropy were the main two contenders here, so added them to the grid search. \n",
      "\n",
      " - Depth: Since each split of the data can have further sub split, this kind of bifuracation helps decision trees to fit data better but this is again only to a certain extent, further increase results in overfitting and reduction in accuracy. \n",
      "\n",
      " - Min Sample split: The minimum number of samples for a particular node so that it can be split. This parameter helps regularizing the tree. \n",
      "\n",
      " - Min Sample leaf: The minimum number of samples for a node to be considered a leaf node, Helps limit the tree growth. \n",
      "\n",
      "\n",
      "Fitting 5 folds for each of 640 candidates, totalling 3200 fits\n"
     ]
    }
   ],
   "source": [
    "# dTree = DecisionTreeClassifier(max_depth=12, criterion=\"entropy\", min_samples_split=4, min_samples_leaf=12)\n",
    "# score = cross_val_score(dTree, X_train, y_bool_train, cv=5)\n",
    "# print(\"DecisionTreeClassifier cross validation score \\n\", score.mean())\n",
    "# dTree.fit(X_train, y_bool_train) \n",
    "# y_pred = dTree.predict(X_test)\n",
    "# print('DecisionTreeClassifier f1 score \\n', f1_score(y_bool_test, y_pred))\n",
    "\n",
    "dTree = DecisionTreeClassifier()\n",
    "# Tried log loss criterion but ran into an error.\n",
    "param_distributions = {\n",
    "    \"criterion\": ['gini', 'entropy'],\n",
    "    \"max_depth\": [7, 8, 9, 10, 11, 12, 13, 14],\n",
    "    \"min_samples_split\": [3, 4, 5, 6, 7],\n",
    "    \"min_samples_leaf\": [7, 8, 9, 10, 11, 12, 13, 14]\n",
    "}\n",
    "\n",
    "print(\"Out of all the tunable parameters in the decision trees. I narrowed down to 4 parameters for the following reasons:\\n\")\n",
    "print(\" - Criterion: This decides which criteria to consider while considering a split to a more specific subset, Gini and entropy were the main two contenders here, so added them to the grid search. \\n\")\n",
    "print(\" - Depth: Since each split of the data can have further sub split, this kind of bifuracation helps decision trees to fit data better but this is again only to a certain extent, further increase results in overfitting and reduction in accuracy. \\n\")\n",
    "print(\" - Min Sample split: The minimum number of samples for a particular node so that it can be split. This parameter helps regularizing the tree. \\n\")\n",
    "print(\" - Min Sample leaf: The minimum number of samples for a node to be considered a leaf node, Helps limit the tree growth. \\n\")\n",
    "print()\n",
    "\n",
    "grid_search_val = GridSearchCV(dTree, param_distributions, verbose=1, n_jobs=-1, cv=5)\n",
    "\n",
    "grid_search_val.fit(X_train, y_bool_train) \n",
    "\n",
    "y_pred = grid_search_val.best_estimator_.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### report final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 results based on the gridsearch:\n",
      "\n",
      "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
      "543       0.185027      0.001706         0.002548        0.000449   \n",
      "507       0.179250      0.002690         0.002140        0.000400   \n",
      "539       0.184471      0.002891         0.002340        0.000395   \n",
      "536       0.184683      0.002091         0.002794        0.000458   \n",
      "535       0.187264      0.004783         0.002616        0.000085   \n",
      "\n",
      "    param_criterion param_max_depth param_min_samples_leaf  \\\n",
      "543         entropy              12                     11   \n",
      "507         entropy              11                     12   \n",
      "539         entropy              12                     10   \n",
      "536         entropy              12                     10   \n",
      "535         entropy              12                     10   \n",
      "\n",
      "    param_min_samples_split  \\\n",
      "543                       6   \n",
      "507                       5   \n",
      "539                       7   \n",
      "536                       4   \n",
      "535                       3   \n",
      "\n",
      "                                                params  split0_test_score  \\\n",
      "543  {'criterion': 'entropy', 'max_depth': 12, 'min...           0.867393   \n",
      "507  {'criterion': 'entropy', 'max_depth': 11, 'min...           0.865274   \n",
      "539  {'criterion': 'entropy', 'max_depth': 12, 'min...           0.869815   \n",
      "536  {'criterion': 'entropy', 'max_depth': 12, 'min...           0.867696   \n",
      "535  {'criterion': 'entropy', 'max_depth': 12, 'min...           0.868907   \n",
      "\n",
      "     split1_test_score  split2_test_score  split3_test_score  \\\n",
      "543           0.864366           0.861296           0.854331   \n",
      "507           0.867393           0.857359           0.854936   \n",
      "539           0.867393           0.856451           0.854634   \n",
      "536           0.866485           0.857359           0.855542   \n",
      "535           0.866788           0.857359           0.854634   \n",
      "\n",
      "     split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
      "543           0.864930         0.862463        0.004506                1  \n",
      "507           0.867050         0.862403        0.005214                2  \n",
      "539           0.863719         0.862402        0.005956                3  \n",
      "536           0.864022         0.862221        0.004892                4  \n",
      "535           0.863113         0.862160        0.005432                5  \n",
      "\n",
      "Q2b. Final model:\n",
      "\n",
      "Best parameters based on the grid search\n",
      "  {'criterion': 'entropy', 'max_depth': 12, 'min_samples_leaf': 11, 'min_samples_split': 6}\n",
      "\n",
      "Best estimator/classifier from the grid search\n",
      "  DecisionTreeClassifier(criterion='entropy', max_depth=12, min_samples_leaf=11,\n",
      "                       min_samples_split=6)\n",
      "VotingClassifier cross validation f1 score \n",
      " 0.8619197864466356\n",
      "\n",
      "VotingClassifier test data classification score\n",
      " 0.8638565891472868\n",
      "\n",
      "VotingClassifier test f1 score \n",
      " 0.8608910891089109\n"
     ]
    }
   ],
   "source": [
    "cv_results = pd.DataFrame(grid_search_val.cv_results_)\n",
    "\n",
    "print(\"Top 5 results based on the gridsearch:\\n\\n\", cv_results.nlargest(5,\"mean_test_score\"))\n",
    "\n",
    "print('\\nQ2b. Final model:')\n",
    "print('\\nBest parameters based on the grid search')\n",
    "print(' ', grid_search_val.best_params_)\n",
    "print('\\nBest estimator/classifier from the grid search')\n",
    "print(' ', grid_search_val.best_estimator_) \n",
    "\n",
    "dtree_score = cross_val_score(grid_search_val.best_estimator_, X_train, y_bool_train, cv=5, scoring='f1')\n",
    "print('VotingClassifier cross validation f1 score \\n', dtree_score.mean())\n",
    "print()\n",
    "print('VotingClassifier test data classification score\\n', accuracy_score(y_bool_test, y_pred))\n",
    "print()\n",
    "print('VotingClassifier test f1 score \\n', f1_score(y_bool_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3a."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier, BaggingClassifier\n",
    "\n",
    "estimator = [\n",
    "('DTree1' , DecisionTreeClassifier(max_depth=12, criterion=\"entropy\", min_samples_split=3, min_samples_leaf=11, max_features='sqrt')),\n",
    "('DTree2' , DecisionTreeClassifier(max_depth=12, criterion=\"entropy\", min_samples_split=3, min_samples_leaf=11, max_features='sqrt')),\n",
    "('DTree3' , DecisionTreeClassifier(max_depth=12, criterion=\"entropy\", min_samples_split=3, min_samples_leaf=11, max_features='sqrt')),\n",
    "('DTree4' , DecisionTreeClassifier(max_depth=12, criterion=\"entropy\", min_samples_split=3, min_samples_leaf=11, max_features='sqrt')),\n",
    "('DTree5' , DecisionTreeClassifier(max_depth=12, criterion=\"entropy\", min_samples_split=3, min_samples_leaf=11, max_features='sqrt')),\n",
    "('DTree6' , DecisionTreeClassifier(max_depth=12, criterion=\"entropy\", min_samples_split=3, min_samples_leaf=11, max_features='sqrt')),\n",
    "('DTree7' , DecisionTreeClassifier(max_depth=12, criterion=\"entropy\", min_samples_split=3, min_samples_leaf=11, max_features='sqrt')),\n",
    "('DTree8' , DecisionTreeClassifier(max_depth=12, criterion=\"entropy\", min_samples_split=3, min_samples_leaf=11, max_features='sqrt')),\n",
    "('DTree9' , DecisionTreeClassifier(max_depth=12, criterion=\"entropy\", min_samples_split=3, min_samples_leaf=11, max_features='sqrt')),\n",
    "('DTree10' , DecisionTreeClassifier(max_depth=12, criterion=\"entropy\", min_samples_split=3, min_samples_leaf=11, max_features='sqrt')),\n",
    "('DTree11' , DecisionTreeClassifier(max_depth=12, criterion=\"entropy\", min_samples_split=3, min_samples_leaf=11, max_features='sqrt')),\n",
    "]\n",
    "\n",
    "eclf = VotingClassifier(estimators=estimator, voting='soft')\n",
    "score = cross_val_score(eclf, X_train, y_bool_train, cv=5, scoring='f1')\n",
    "eclf.fit(X_train, y_bool_train)\n",
    "y_pred = eclf.predict(X_test)\n",
    "\n",
    "# Vs 0.8628266"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q3a. conclusion:\n",
      "VotingClassifier f1 cross validation score \n",
      " 0.878062028556642\n",
      "VotingClassifier classification \n",
      " 0.8670058139534884\n",
      "VotingClassifier f1 score \n",
      " 0.8652760736196319\n",
      "\n",
      "Voting Classifier overall performs slightly better with a f1 score of 0.876 compared to 0.8619 in only Dtree classifier. Changing the voting to hard does improve it a bit but not by too much. Additionally since the voting process is more democratised there are less chances for outlier to influence the decision of a voting classifier compared to D tree.In general, ensemble models combine multiple base models to improve the predicting performance\n"
     ]
    }
   ],
   "source": [
    "print('Q3a. conclusion:')\n",
    "\n",
    "print('VotingClassifier f1 cross validation score \\n', score.mean())\n",
    "print('VotingClassifier classification \\n', accuracy_score(y_bool_test, y_pred))\n",
    "print('VotingClassifier f1 score \\n', f1_score(y_bool_test, y_pred))\n",
    "\n",
    "print('\\nVoting Classifier overall performs slightly better with a f1 score of 0.876 compared to 0.8619 in only Dtree classifier. Changing the voting to hard does improve it a bit but not by too much. Additionally since the voting process is more democratised there are less chances for outlier to influence the decision of a voting classifier compared to D tree.In general, ensemble models combine multiple base models to improve the predicting performance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3b."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier()\n",
    "\n",
    "# Comment the below 2 lines after the first run.\n",
    "for idx in range(0, 11, 1):\n",
    "    estimator.append(('KNN'+ str(idx),  model))\n",
    "    \n",
    "eclfNew = VotingClassifier(estimators=estimator, voting='soft')\n",
    "score = cross_val_score(eclfNew, X_train, y_bool_train, cv=5, scoring='f1')\n",
    "eclf.fit(X_train, y_bool_train)\n",
    "y_pred = eclf.predict(X_test)\n",
    "# Vs 0.8628266"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q3b. conclusion:\n",
      "VotingClassifier f1 cross validation score \n",
      " 0.8261171056369274\n",
      "VotingClassifier classification \n",
      " 0.8403585271317829\n",
      "VotingClassifier f1 score \n",
      " 0.8367599702749566\n",
      "\n",
      "Decision trees build a classification model based on the training set and arent the best at learning an unforeseen observation, as compared to KNN which models well to test data on the spot, because of this the two models performance on the dataset would vary quite a bit and their collective voting would skew the results. Additionally, decision trees are known to prune data points that are rare occurrences compared to KNN which would handle them better, this would also result in a more skewed voting result. Finally, based on this observation its ideal to not combine models that work differently in a counterproductive way\n"
     ]
    }
   ],
   "source": [
    "print('Q3b. conclusion:')\n",
    "\n",
    "print('VotingClassifier f1 cross validation score \\n', score.mean())\n",
    "\n",
    "print('VotingClassifier classification \\n', accuracy_score(y_bool_test, y_pred))\n",
    "print('VotingClassifier f1 score \\n', f1_score(y_bool_test, y_pred))\n",
    "print()\n",
    "\n",
    "print('Decision trees build a classification model based on the training set and arent the best at learning an unforeseen observation, as compared to KNN which models well to test data on the spot, because of this the two models performance on the dataset would vary quite a bit and their collective voting would skew the results. Additionally, decision trees are known to prune data points that are rare occurrences compared to KNN which would handle them better, this would also result in a more skewed voting result. Finally, based on this observation its ideal to not combine models that work differently in a counterproductive way')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3c."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "bagging = BaggingClassifier(DecisionTreeClassifier(max_depth=12, criterion=\"entropy\", min_samples_split=3, min_samples_leaf=11))\n",
    "param_distributions = {\n",
    "    \"max_features\": [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
    "}\n",
    "\n",
    "grid_search_val = GridSearchCV(bagging, param_distributions, verbose=1, n_jobs=-1, cv=5)\n",
    "\n",
    "grid_search_val.fit(X_train, y_bool_train) \n",
    "\n",
    "y_pred = grid_search_val.best_estimator_.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### report best model and performance on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q3c.\n",
      "Best parameters based on the grid search {'max_features': 0.7}\n",
      "Best Estimator model based on the grid search BaggingClassifier(base_estimator=DecisionTreeClassifier(criterion='entropy',\n",
      "                                                        max_depth=12,\n",
      "                                                        min_samples_leaf=11,\n",
      "                                                        min_samples_split=3),\n",
      "                  max_features=0.7)\n",
      "\n",
      "BaggingClassifier test classification \n",
      " 0.9045542635658915\n",
      "BaggingClassifier test f1 score \n",
      " 0.9030988686669945\n"
     ]
    }
   ],
   "source": [
    "print('Q3c.')\n",
    "\n",
    "print('Best parameters based on the grid search', grid_search_val.best_params_)\n",
    "print('Best Estimator model based on the grid search', grid_search_val.best_estimator_) \n",
    "\n",
    "print()\n",
    "print('BaggingClassifier test classification \\n', accuracy_score(y_bool_test, y_pred))\n",
    "print('BaggingClassifier test f1 score \\n', f1_score(y_bool_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3d."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier, GradientBoostingClassifier, HistGradientBoostingClassifier\n",
    "\n",
    "eclf_new_ada = AdaBoostClassifier()\n",
    "score_ada = cross_val_score(eclf_new_ada, X_train, y_bool_train, cv=5, scoring='f1')\n",
    "eclf_new_ada.fit(X_train, y_bool_train)\n",
    "y_pred_ada = eclf_new_ada.predict(X_test)\n",
    "\n",
    "eclf_new_GBC = GradientBoostingClassifier()\n",
    "score_GBC = cross_val_score(eclf_new_GBC, X_train, y_bool_train, cv=5, scoring='f1')\n",
    "\n",
    "eclf_new_GBC.fit(X_train, y_bool_train)\n",
    "y_pred_GBC = eclf_new_GBC.predict(X_test)\n",
    "\n",
    "eclf_new_RFC = RandomForestClassifier()\n",
    "score_RFC = cross_val_score(eclf_new_RFC, X_train, y_bool_train, cv=5, scoring='f1')\n",
    "eclf_new_RFC.fit(X_train, y_bool_train)\n",
    "y_pred_RFC = eclf_new_RFC.predict(X_test)\n",
    "\n",
    "eclf_new_ETC = ExtraTreesClassifier()\n",
    "score_ETC = cross_val_score(eclf_new_ETC, X_train, y_bool_train, cv=5, scoring='f1')\n",
    "eclf_new_ETC.fit(X_train, y_bool_train)\n",
    "y_pred_ETC = eclf_new_ETC.predict(X_test)\n",
    "\n",
    "eclf_new_hist = HistGradientBoostingClassifier()\n",
    "score_hist = cross_val_score(eclf_new_hist, X_train, y_bool_train, cv=5, scoring='f1')\n",
    "eclf_new_hist.fit(X_train, y_bool_train)\n",
    "y_pred_hist = eclf_new_hist.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### report result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q3d.\n",
      "AdaBoostClassifier cross validation score\n",
      " 0.861553772431904\n",
      "AdaBoostClassifier test classification \n",
      " 0.8599806201550387\n",
      "AdaBoostClassifier test f1 score \n",
      " 0.8584027437530621\n",
      "\n",
      "GradientBoostingClassifier cross validation score\n",
      " 0.8854707221417456\n",
      "GradientBoostingClassifier test classification \n",
      " 0.8788759689922481\n",
      "GradientBoostingClassifier test f1 score \n",
      " 0.8773908778813142\n",
      "\n",
      "RandomForestClassifier cross validation score\n",
      " 0.8904190793093092\n",
      "RandomForestClassifier test classification \n",
      " 0.8943798449612403\n",
      "RandomForestClassifier test f1 score \n",
      " 0.8920257553244181\n",
      "\n",
      "ExtraTreesClassifier cross validation score\n",
      " 0.8961611021276248\n",
      "ExtraTreesClassifier test classification \n",
      " 0.8980135658914729\n",
      "ExtraTreesClassifier test f1 score \n",
      " 0.8960237095579155\n",
      "\n",
      "HistGradientBoostingClassifier cross validation score\n",
      " 0.9019723105223209\n",
      "HistGradientBoostingClassifier test classification \n",
      " 0.905765503875969\n",
      "HistGradientBoostingClassifier test f1 score \n",
      " 0.9043050430504306\n",
      "Out of all the models, histogram classifier has the best performance on the dataset.\n"
     ]
    }
   ],
   "source": [
    "print('Q3d.')\n",
    "print(\"AdaBoostClassifier cross validation score\\n\", score_ada.mean())\n",
    "print('AdaBoostClassifier test classification \\n', accuracy_score(y_bool_test, y_pred_ada))\n",
    "print('AdaBoostClassifier test f1 score \\n', f1_score(y_bool_test, y_pred_ada))\n",
    "\n",
    "print(\"\\nGradientBoostingClassifier cross validation score\\n\", score_GBC.mean())\n",
    "print('GradientBoostingClassifier test classification \\n', accuracy_score(y_bool_test, y_pred_GBC))\n",
    "print('GradientBoostingClassifier test f1 score \\n', f1_score(y_bool_test, y_pred_GBC))\n",
    "\n",
    "print(\"\\nRandomForestClassifier cross validation score\\n\", score_RFC.mean())\n",
    "print('RandomForestClassifier test classification \\n', accuracy_score(y_bool_test, y_pred_RFC))\n",
    "print('RandomForestClassifier test f1 score \\n', f1_score(y_bool_test, y_pred_RFC))\n",
    "\n",
    "print(\"\\nExtraTreesClassifier cross validation score\\n\", score_ETC.mean())\n",
    "print('ExtraTreesClassifier test classification \\n', accuracy_score(y_bool_test, y_pred_ETC))\n",
    "print('ExtraTreesClassifier test f1 score \\n', f1_score(y_bool_test, y_pred_ETC))\n",
    "\n",
    "print(\"\\nHistGradientBoostingClassifier cross validation score\\n\", score_hist.mean())\n",
    "print('HistGradientBoostingClassifier test classification \\n', accuracy_score(y_bool_test, y_pred_hist))\n",
    "print('HistGradientBoostingClassifier test f1 score \\n', f1_score(y_bool_test, y_pred_hist))\n",
    "\n",
    "print(\"Out of all the models, histogram classifier has the best performance on the dataset.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
